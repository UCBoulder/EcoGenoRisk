{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#Initial Imports\n",
    "import gzip#; print('gzip version: ', gzip.__version__)\n",
    "import os#; print('os version: ', os.__version__)\n",
    "import re#; print('re version: ', re.__version__)\n",
    "import shutil#; print('shutil version: ', shutil.__version__)\n",
    "import requests#; print('requests version: ', requests.__version__)\n",
    "import wget#; print('wget version: ', wget.__version__)\n",
    "import subprocess#; print('subprocess version: ', subprocess.__version__)\n",
    "import time#; print('time version: ', time.__version__)\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE, Popen\n",
    "from fake_useragent import UserAgent\n",
    "import os.path\n",
    "from os import path\n",
    "from Bio.ExPASy import Enzyme\n",
    "import numpy as np \n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "red = \"\\033[91m\"\n",
    "reset_color = \"\\033[0m\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JGI_Soil_Genomes in this script can be thought of as the \"Home\" folder. Everything will branch out from there. When moving to the HPC, the equivalent will be the 'EnCen' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Unitprot.fasta for Use in Diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_to_fasta():\n",
    "    reference_library = 'uniprot.tsv' \n",
    "    #this creates a file named 'uniprot.tsv' on the working directory. Should show within the EcoDr/EcoDr folder. \n",
    "    ua = UserAgent()\n",
    "    header = {'User-Agent': str(ua.chrome)}\n",
    "    uniprot_url = 'https://rest.uniprot.org/uniprotkb/stream?fields=accession%2Cec%2Csequence&format=tsv&query=%28%28ec%3A*%29%29+AND+%28reviewed%3Atrue%29'\n",
    "    time.sleep(4)\n",
    "    uniprot = requests.get(uniprot_url, headers=header)\n",
    "    if uniprot.status_code == 200:\n",
    "        with open(reference_library, 'w+') as reference_library:\n",
    "            reference_library.write(uniprot.text)\n",
    "    print('Uniprot Reference File Has Been Created')\n",
    "####this step takes it the initial tsv and converts it to FASTA\n",
    "    input = os.path.abspath('uniprot.tsv')\n",
    "    output = 'uniprot.fasta'\n",
    "    with open(input, 'r') as input_file, open(output, 'w') as output_file:\n",
    "        header=next(input_file)\n",
    "        for line in input_file:\n",
    "            carrot = f'>{line}'\n",
    "            new_row = re.sub(r'(.*?\\t.*?)\\t', r'\\1\\n', carrot, 1)\n",
    "            new_row_with_tab_replaced_by_question_mark = new_row.replace(\"\\t\", \"?\")\n",
    "            # Be careful with the symbols used for replacement, as they have to align with the genomic summary string parsing\n",
    "            output_row_with_space_replaced_with_ampersand = new_row_with_tab_replaced_by_question_mark.replace(\"; \", \";_\")\n",
    "            #new_row2 = re.sub(r'(.*?\\t.*?)\\t', r'$', new_row, 0)\n",
    "            #this is regex, for the record. \n",
    "            output_file.write(output_row_with_space_replaced_with_ampersand)\n",
    "    print('FASTA has been created from TSV and is named', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC List Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EC_extract():\n",
    "    ec_library = 'EC_library.csv' \n",
    "    ua = UserAgent()\n",
    "    header = {'User-Agent': str(ua.chrome)}\n",
    "    ec_url = 'https://ftp.expasy.org/databases/enzyme/enzyme.dat'\n",
    "    time.sleep(4)\n",
    "    ec = requests.get(ec_url, headers=header)\n",
    "    if ec.status_code == 200:\n",
    "        with open(ec_library, 'w+', newline='\\n') as ec_file:\n",
    "            ec_file.write(ec.text)\n",
    "###This step creates the list \n",
    "    handle = open(ec_library)\n",
    "    records = Enzyme.parse(handle)\n",
    "    ecnumbers = [record[\"ID\"] for record in records]\n",
    "    #print(type(ecnumbers)) #This is a list at this point in the code\n",
    "    path = os.path.abspath(ec_library)\n",
    "    with open(path, 'w+', newline='\\n') as csv_file:\n",
    "        #csv_file = csv.writer(csv_file)\n",
    "        for item in ecnumbers:\n",
    "            csv_file.write(item +'\\n')\n",
    "    print('EC list Has Been Created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diamond_impl(dest, name):\n",
    "    print(os.getcwd())\n",
    "    matches = ''\n",
    "    output_folder = dest \n",
    "    final_folder = '/home/anna/Documents/JGI_soil_genomes/diamond_analysis_output'\n",
    "    print(\"DIAMOND library is located in: \", output_folder)\n",
    "    if os.path.isfile('/home/anna/Documents/JGI_soil_genomes/Soil_Metagenome_Test/Uniprot_Reference_Library.dmnd'):\n",
    "        print(\"Library Detected\")\n",
    "    # If not present, then creates a DIAMOND library by referencing the exact location where the Uniprot library is saved\n",
    "    # If there currently is no reference library (.dmnd), then command makedb creates a DIAMOND library\n",
    "    else:\n",
    "        print(\"Creation of DIAMOND-formatted library...\")\n",
    "        makedb = ['diamond', 'makedb', '--in', '/home/anna/Documents/JGI_soil_genomes/uniprot.fasta', '-d',\n",
    "                  'Uniprot_Reference_Library.dmnd']  # Reference library full pathway\n",
    "        #This is a list for the DIAMOND specific makedb function. \n",
    "        subprocess.run(makedb)\n",
    "        #This simply runs the function makedb\n",
    "        print(\"Library complete\")\n",
    "#^this chunk is good to go. Just makes the reference database from the uniprot fasta. \n",
    "###_______________________________________________________________# This portion does the matching. The above portion creates the reference library from the unitprot fasta\n",
    "    for item in os.listdir(dest):\n",
    "        # Checks for file extension\n",
    "        if item.endswith('.faa') and not os.path.isfile(\n",
    "                os.path.basename(os.path.abspath(item)).rsplit('.', 1)[0] + \"_matches.tsv\"):\n",
    "            # Finds path of file\n",
    "            file_path = os.path.abspath(item)\n",
    "            # Finds the GCF/ASM name of the file by looking at the first part of the name before the .faa notation\n",
    "            if name == \"\":\n",
    "                print(os.path.basename(file_path).rsplit('.',1))\n",
    "                file_name = (os.path.basename(file_path)).rsplit('.', 1)[0]\n",
    "            else:\n",
    "                file_name = name\n",
    "            # New filename that ends with matches\n",
    "            matches = file_name + \"_matches.tsv\"\n",
    "            # print(matches)\n",
    "            # If genome has not already undergone DIAMOND search and is currently located in the correct folder, then\n",
    "            # the subprocess function will run the diamond search\n",
    "            if not os.path.isfile(dest + \"/\" + matches) and os.path.abspath(matches) != output_folder:\n",
    "                print(\"Processing \", file_name)\n",
    "                # DIAMOND search using the full pathway of the protein files, max target sequence outputs only one best\n",
    "                # match with highest e-value which represent the chance of obtaining a better random match in the same database (Buchfink et al, 2021)\n",
    "                blastp = ['diamond', 'blastp', '-d', 'Uniprot_Reference_Library.dmnd', '-q', file_path, '-o', matches, \n",
    "                          '--max-target-seqs', '1', '--outfmt', '6']\n",
    "                time.sleep(4)\n",
    "                subprocess.run(blastp)\n",
    "    \n",
    "\n",
    "    # Moves all DIAMOND search outputs into the folder\n",
    "        if item.endswith('.tsv'):\n",
    "            if os.path.exists(os.path.join(final_folder, item)):\n",
    "                print(f\"Overwriting: {item}\")\n",
    "                os.remove(os.path.join(final_folder, item))\n",
    "            shutil.move(os.path.abspath(item), final_folder)\n",
    "    print(\"diamond_impl--success\")\n",
    "    # Returns the location of the DIAMOND matches folder\n",
    "    return output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genome Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_extractor(diamond_folder, name):\n",
    "    os.chdir(diamond_folder)\n",
    "    print(os.getcwd())\n",
    "    # Opens the list of of EC numbers\n",
    "    ec_open = np.loadtxt('/home/anna/Documents/JGI_soil_genomes/EC_library.csv',\n",
    "                         dtype='str')\n",
    "    big_matrix = [\"Name_of_Genome\"]\n",
    "    file_name = name + '_functional_profile'\n",
    "    new_dir = diamond_folder + '/' + file_name\n",
    "    # Checks to see if the document already exists using full pathway name\n",
    "    if os.path.exists(new_dir):\n",
    "        pass\n",
    "        #print(\"Summary Matrix exists\")\n",
    "        #return [new_dir, file_name]\n",
    "    else:\n",
    "        for ec_force in ec_open:\n",
    "            # Creates a horizontal header of all of the EC names\n",
    "            big_matrix.append(ec_force)\n",
    "   \n",
    "        for item in os.listdir(diamond_folder):\n",
    "            if item.endswith(\"_matches.tsv\"):\n",
    "                print(item)\n",
    "                genome = [item] #Turns the GCF's into a list, where the GCF names in the matrix come from. \n",
    "                genome_runner_ec = [item] #Turns the GCF's into a list, where the EC is appended\n",
    "                # Iterates through all of the EC numbers (1:8197)\n",
    "                \n",
    "                GCF = open(item, 'r') # CBM Added\n",
    "                \n",
    "                for line in GCF: # CBM Added\n",
    "                    no_tab = line.split('\\t')\n",
    "                    first_ec = no_tab[1].split(\"?\")\n",
    "                    separate_ec = first_ec[1].split(\";_\")\n",
    "                    genome_runner_ec.append(separate_ec)\n",
    "                    print(\"Appending...\")\n",
    "\n",
    "                for ec in ec_open:\n",
    "                 \n",
    "                    ec_now = 0\n",
    "                    if [ec] in genome_runner_ec:\n",
    "                        ec_now = 1\n",
    "\n",
    "                    # 1 or 0 will be appended to the summary matrix for each EC value in the list\n",
    "                    genome.append(ec_now)\n",
    "                    #print(genome)\n",
    "                # Vertical stacking occurs for each genome in the DIAMOND output folder\n",
    "                big_matrix = np.vstack([big_matrix, genome])\n",
    "        #print(big_matrix)\n",
    "        # Saves matrix as a text file for further analysis\n",
    "        np.savetxt(file_name, big_matrix, fmt='%s')\n",
    "        # Returns the location of the summary matrix and the name of the file\n",
    "        if not os.path.exists(os.path.abspath(file_name)):\n",
    "            shutil.move(os.path.abspath(file_name),'/home/anna/Documents/JGI_soil_genomes')\n",
    "        else:\n",
    "            print('File already Exists')\n",
    "        print(new_dir)\n",
    "    return [new_dir, file_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metagenome_name = 'diamond_analysis_output' #-> folder\n",
    "desired_location = '/home/anna/Documents/JGI_soil_genomes' #/home/anna/Documents/Rare_Funcs_Act_sludge\n",
    "# Freshwater = nump/nump/nump/files\n",
    "soil = '/home/anna/Documents/JGI_soil_genomes/Soil_Metagenome_Test' #/home/anna/Documents/Rare_Funcs_Act_sludge/Bins\n",
    "abspath = os.path.abspath(soil)\n",
    "name = 'bin_metagenome'\n",
    "\n",
    "#!Turn these back on when doing it on SP \n",
    "# EC_extract()\n",
    "# tsv_to_fasta()\n",
    "\n",
    "#______________________________________________________________#\n",
    "os.chdir(desired_location) #-> we are in the folder we want\n",
    "if os.path.exists(metagenome_name):\n",
    "    shutil.rmtree(metagenome_name)\n",
    "    os.mkdir(metagenome_name)\n",
    "else:#makes a new directory called metagenome_name\n",
    "    os.mkdir(metagenome_name)\n",
    "desired_location = desired_location + \"/\" + metagenome_name \n",
    "# shutil.copy(abspath, desired_location) #moves  file to Test Cases folder\n",
    "#matches = metagenome + \"_matches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(soil)\n",
    "diamond = diamond_impl(soil, '') #-> Takes in the path and directory\n",
    "# new_dir, saved_file_name = genome_extractor(desired_location, '') #-> At this point, we have the one hotted binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_folder = '/home/anna/Documents/JGI_soil_genomes/diamond_analysis_output' #/home/anna/Documents/Rare_Funcs_Act_sludge/Diamond\n",
    "desired_location = '/home/anna/Documents/JGI_soil_genomes/Soil_Metagenome_Test' #/home/anna/Documents/Rare_Funcs_Act_sludge/Bins\n",
    "ff_name = 'functional_profiles'\n",
    "functional_folder = '/home/anna/Documents/JGI_soil_genomes/functional_profiles' #/home/anna/Documents/Rare_Funcs_Act_sludge/functional_profiles\n",
    "\n",
    "# print(desired_location)\n",
    "for item in os.listdir(desired_location):\n",
    "    if item.endswith(('_matches.tsv', '.dmnd')):\n",
    "        source = os.path.join(desired_location, item)\n",
    "        destination = os.path.join(final_folder, item)\n",
    "        shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond has found protein matches between the reference and the metagenome.faa's. They, along with the diamond library, are now in \"diamond_analysis_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anna/Documents/JGI_soil_genomes/diamond_analysis_output\n"
     ]
    }
   ],
   "source": [
    "output = genome_extractor(final_folder, name)\n",
    "\n",
    "os.chdir('/home/anna/Documents/JGI_soil_genomes') #/home/anna/Documents/Rare_Funcs_Act_sludge\n",
    "if os.path.exists(functional_folder):\n",
    "    shutil.rmtree(ff_name)\n",
    "    os.mkdir(ff_name)\n",
    "else:#makes a new directory called metagenome_name\n",
    "    os.mkdir(ff_name)\n",
    "\n",
    "for item in os.listdir(final_folder):\n",
    "    if item.endswith('_profile'):\n",
    "        source = os.path.join(final_folder, item)\n",
    "        destination = os.path.join(functional_folder, item)\n",
    "        shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We Now Have the functional profile of the entire metagenome. It has been created and moved to the functional profiles folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Next Steps is to make the functional profile out of the synbio.faa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synbio directory already exists\n",
      "\u001b[91mATTENTION USER: SYNBIO OR COMPARISON ORGANISM .FAA MUST BE IN THE SYNBIO INPUTS AND OUTPUTS FOLDER. \n",
      " OTHERWISE, SCRIPT WILL CRASH\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "synbio = '/home/anna/Documents/JGI_soil_genomes/synbio_inputs_and_outputs'\n",
    "name = 'Synbio'\n",
    "syn_folder_name = 'synbio_inputs_and_outputs'\n",
    "desired_location2 = '/home/anna/Documents/JGI_soil_genomes'\n",
    "\n",
    "os.chdir('/home/anna/Documents/JGI_soil_genomes')\n",
    "if os.path.exists(synbio):\n",
    "   print('Synbio directory already exists')\n",
    "else:#makes a new directory called metagenome_name\n",
    "    os.mkdir(syn_folder_name)\n",
    "\n",
    "print(f'{red}ATTENTION USER: SYNBIO OR COMPARISON ORGANISM .FAA MUST BE IN THE SYNBIO INPUTS AND OUTPUTS FOLDER. \\n OTHERWISE, SCRIPT WILL CRASH{reset_color}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(synbio) \n",
    "diamond_syn = diamond_impl(synbio, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anna/Documents/JGI_soil_genomes/synbio_inputs_and_outputs\n"
     ]
    }
   ],
   "source": [
    "output2 = genome_extractor(diamond_syn, name)\n",
    "for item in os.listdir(synbio):\n",
    "    if item.endswith('_profile'):\n",
    "        source = os.path.join(synbio, item)\n",
    "        destination = os.path.join(functional_folder, item)\n",
    "        shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synbio Functional Profile is now created. We now have both the environmental profile and the synbio profile. From Here down is distance scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "synbio_binary = '/home/anna/Documents/JGI_soil_genomes/functional_profiles/Synbio_functional_profile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_to_genome_diffcomp(synbio_binary, domain_binary):\n",
    "    names_of_orgs = pd.DataFrame(domain_binary.index) \n",
    "    diff = pd.DataFrame(abs(domain_binary.values - synbio_binary.values)) \n",
    "    row_sum = diff.sum(axis=1)\n",
    "    df1 = pd.DataFrame(row_sum)\n",
    "    difference_based_comparison = pd.concat([names_of_orgs, df1], axis=1)\n",
    "    difference_based_comparison.columns = ['Organisms Compared to Synbio', 'Difference Score']\n",
    "    difference_based_comparison = difference_based_comparison.sort_values(by='Difference Score',\n",
    "                                                                          ignore_index=True).reset_index(drop=True)\n",
    "    difference_based_comparison.to_csv('Absolute_Difference_Comparison_Score.txt', header=True, index=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_binary_matrix(synbio_binary, sb_name):\n",
    "    # Converts synbio summary matrix into a dataframe\n",
    "    synbio_binary = pd.read_csv(synbio_binary, delimiter=\" \", header=0)\n",
    "    # print(synbio_binary)\n",
    "    synbio_binary = synbio_binary.set_index('Name_of_Genome')\n",
    "    #index is a label for all rows - allows the two seperate dataframes to come together since they share an index\n",
    "    # print(synbio_binary)\n",
    "    print(sb_name, \" size of \", np.shape(synbio_binary), \" successfully imported.\")\n",
    "    # Opens the matrix that includes the Bacteria and Archaea summary result\n",
    "    domain_binary = pd.read_csv('/home/anna/Documents/JGI_soil_genomes/functional_profiles/soil_metagenome_functional_profile',\n",
    "                                  delimiter=\" \", header=0)\n",
    "    #this is from chunk 1, and is the EC_Binary we generated earlier\n",
    "    domain_binary = domain_binary.set_index('Name_of_Genome')\n",
    "    # print(domain_binary)\n",
    "    # Sends to a function for direct genome to genome comparison based on EC summary matrix\n",
    "    genome_to_genome_diffcomp(synbio_binary, domain_binary)\n",
    "    synbio_bacteria = pd.concat([domain_binary, synbio_binary])\n",
    "    # Verically adding synbio matrix to the overall matrix to complete the comparison, therefore last index\n",
    "    # should represent the synbio genome that is tested and returned as distances_mat[-1,:] in pass_to_distance.\n",
    "    # Note, headers are lost and need to be directly passed\n",
    "    # print(\"Shape of combined matrix using append is: \", np.shape(synbio_bacteria))\n",
    "    print(\"Merging of bacteria data and synbio data is complete\")\n",
    "    doc_name_1 = 'combined_synbio_metagenome_binary_matrix.txt'\n",
    "    # Removes any duplicates\n",
    "    all_matrix = synbio_bacteria[~synbio_bacteria.index.duplicated(keep='first')]\n",
    "    # print(all_matrix)\n",
    "    all_matrix.to_csv(doc_name_1, header=True, index=True, sep='\\t')\n",
    "    return all_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_distance(input_df, genome_names,genome_ID):\n",
    "    #calculating_distance(clustered_ec, list_genomes, clustering_pref, index_names, sb_name, rank)\n",
    "    # Calculate the distances of the datafile using the pdist funciton from scipy. The intial return will only\n",
    "    # provide the upper half of the comparisons (row-wise) to create a symetrical matrix then create squareform\n",
    "    name = genome_ID + '_Euclidean' + '_non_pairwise_distance_result.txt'\n",
    "    distances_parallel = pairwise_distances(X=input_df, metric='euclidean', n_jobs=18)\n",
    "    #imported function that takes in the ec, calculates the distance between rows, n_jobs is for large datasets\n",
    "    # print(\"Shape of the entire distance matrix is: \", np.shape(distances_parallel))\n",
    "    # NaNs at this stage may indicate header name mismatch - check if EC numbers are aligning\n",
    "    # If wanting to save the full distance matrix, then turn the following flag on. Note: Well above 10 GB\n",
    "    distances_parallel = pd.DataFrame(distances_parallel)\n",
    "    # print(distances_parallel)\n",
    "    #print('Chocolate Sunday')\n",
    "    # Returns the full distance matrix for dendrogram construction in R script\n",
    "    #distances_parallel.to_csv('diff_weighted_unclustered_distance_matrix.txt', header=False, index=False, sep='\\t')\n",
    "    #distances_parallel.to_csv('both_chimeras_distance_matrix_clustered.txt', header=False, index=False, sep='\\t')\n",
    "    # print(\"Distance matrix is downloaded\")\n",
    "    # print(genome_names)\n",
    "    # Converts the distance matrix of synbio as a data frame. Concat binds the row names dataframe with the synbio distance\n",
    "    # matrix. Result should be a [2,#of total genomes]\n",
    "    distances_synbio = pd.concat([genome_names.reset_index(drop=True),\n",
    "                                    distances_parallel.reset_index(drop=True)], axis=1)\n",
    "    #axis=1 is the columns. Just adds genome names to the final score output\n",
    "    distances_parallel.index = genome_names['Name_of_Genome'].tolist()\n",
    "    distances_parallel.to_csv('Euclidean_pairwise_distance_results.txt', header = True, index = True, sep='\\t')\n",
    "    #distances_parallel.set_index('Name_of_Genome', inplace=True, drop=True)\n",
    "    # Finds the row that contains the synbio genome based on genome ID\n",
    "    tsv_name = genome_ID.replace(\".faa\", \"\")\n",
    "    tsv_name2 = tsv_name + \"_matches.tsv\"\n",
    "    # print(tsv_name2)\n",
    "    synbio_row = distances_parallel.loc[tsv_name2 ,:]\n",
    "    #grabs the name of the first GCF using the index\n",
    "    synbio_column = synbio_row.T\n",
    "    # Creates the vertical genome names for the resulting matrix\n",
    "    synbio_column.index = genome_names\n",
    "    # Sets column names\n",
    "    synbio_column.columns = ['Genome_Name', 'Calculated Distance']\n",
    "    return synbio_column, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_to_distance(synbio_binary, sb_name, desired_location):\n",
    "    all_matrix = read_in_binary_matrix(synbio_binary, sb_name)\n",
    "    list_genomes = pd.DataFrame(all_matrix.index)\n",
    "    # Completes distance calculation on an Euclidean basis. Returns the synbio column with genome names appended\n",
    "    [synbio_clustered_distances, name] = calculating_distance(all_matrix, list_genomes, sb_name)\n",
    "    \n",
    "    synbio_clustered_distances.to_csv(name, header=True, index=True, sep='\\t')\n",
    "    return synbio_clustered_distances, desired_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synbio  size of  (1, 8236)  successfully imported.\n",
      "Merging of bacteria data and synbio data is complete\n",
      "Synbio Analysis Complete\n"
     ]
    }
   ],
   "source": [
    "# synbio = '/home/anna/Documents/JGI_soil_genomes/Synbio/'\n",
    "# name = 'Synbio_Functional_Profile'\n",
    "# desired_location2 = '/home/anna/Documents/JGI_soil_genomes'\n",
    "# synbio binary is the synbio functional profile. \n",
    "[distance_list_for_synbio, new_loc ]= pass_to_distance(synbio_binary, name, desired_location2)\n",
    "print('Synbio Analysis Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Distance Scoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
